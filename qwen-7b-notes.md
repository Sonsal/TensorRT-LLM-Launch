## Qwen2.5-7B-Instruct
`!trtllm-serve --tokenizer "TensorRT-LLM/examples/qwen/7B" --max_batch_size 1 --max_num_tokens 4096 --max_seq_len 4096 "TensorRT-LLM/examples/qwen/7B/trt_engines/fp16/1-gpu/"`

**Файл**: TensorRT-LLM-Qwen2-5-7B-0-17-0.ipynb

Duration:  29.720160245895386
Tokens/s:  40.746728500674806

